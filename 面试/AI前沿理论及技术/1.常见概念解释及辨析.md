## Memory

现如今的AI大模型公司提供的最常见的，普通人最常用的就是**推理服务**。我们使用的ChatGPT、Deepseek等大模型，本质是一个超大型文件，其中存放的是训练得到的各种参数，为了让这个文件运行并和外界进行交互，需要将文件加载到内存中并向外暴露Http接口用于交互。

在日常与AI进行交流时，企业为了能抗住大量的请求，在后端会起多个推理服务实例，你的发起的不同对话，可能是在不同的推理服务实例上进行推理反馈的。

虽然可能在不同的推理服务上进行推理，但是日常使用时，并不会觉得它记不住我说过的内容。其实大模型是没有记忆功能的！在每次大模型进行推理时，都会将以前的聊天内容（上下文）附加上，使得大模型感觉起来是具有记忆功能的。但是不可能将所有的对话记录全部一口气给大模型，这样是非常消耗token和时间的，为了改善面临的环境，提供一种机制——**Memory**，此机制将最近几次对话内容完整保存，称为**短期记忆**。将许久之前的对话提取关键信息，压缩总结，称为**长期记忆**。

## RAG

检索增强生成。大模型的参数是基于互联网上的内容进行训练的，很可能不是很符合公司或者个人的需要。此时，可以为大模型准备一份“参考答案”——外部知识库。

RAG的核心原理是通过检索外部知识库得到与交互相关的内容，并将内容和问题一并发送给大模型。使得大模型推理得到的结果具有更高的准确性。

## MCP

尽管通过Memory和RAG可以使得大模型变得更加专业和聪明，但是它并没有真正与外部世界进行交互的能力——使用工具，比如：发送邮件、修改本地代码等。

MCP就是为提供上述功能所形成的一套工程化协议。在对话里约定一种消息格式，外部服务告诉大模型有哪些工具可以使用，大模型要使用工具时，输出一段规定格式的json给外部服务，外部服务接受到json后，根据json中的内容执行操作，操作完成后将得到的结果返回给大模型，大模型就能根据返回内容生成最终回复了。

外部服务称为**MCP Host**，比如：Cursor、ClaudeCode等。能被调用的具体工具称为**MCP插件**，MCP插件还可以被拆分为本地的**MCP Client**和远端的**MCP Server**。MCP Host和MCP Client一般是集成的，Client会让MCP Server去执行相应操作。

## Skills

MCP为大模型提供了得力的工具，但是仍然缺乏经验——不知道在什么时候什么场景进行调用什么工具。Skills就是为了解决这样的困境而诞生的。提供一份执行流程说明书，大模型就可以清楚怎样去调用工具了。

## Agent

通过上述的各种技术构建的AI系统被称为**AI Agent**！

